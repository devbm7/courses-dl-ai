{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why to use finetuning?**\n",
    "- Fit more data than what fits into the prompt.\n",
    "- Learns from the data rather than just get access to it.\n",
    "- Deeper control of the LLM to achieve what you want.\n",
    "- Cheaper than running huge prompts in RAG\n",
    "- Parameter efficient finetuning (PEFT) reduces cost by 10000 times.\n",
    "- Mixture of Memory Experts (MoME) turn any model into mixture of expert adapters, reducing time by 240 times.\n",
    "\n",
    "![Image](PEFTvsMoME.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations of fine tuning**\n",
    "- Takes more compute to get the same accuracy.\n",
    "- Can't parallelize efficiently across multiple GPUs.\n",
    "- Crash on the real use case, can't continuously finetune & inference together in production.\n",
    "- LLM doesn't improve - hard to tune for each usecase, model or dataset.\n",
    "- Integrating finetuning with internface is full of bugs \n",
    "- Using wrong tools for the job. e.g. Intruction-finetuning doesn't solve hallucination."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
